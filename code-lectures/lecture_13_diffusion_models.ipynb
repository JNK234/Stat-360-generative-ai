{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_checkerboard,make_circles,make_moons,make_s_curve,make_swiss_roll\n",
    "from helper_plot import hdr_plot_style\n",
    "import torch\n",
    "from diffusion_utils import extract, noise_estimation_loss\n",
    "\n",
    "hdr_plot_style()\n",
    "swiss_roll, _ = make_swiss_roll(10**4,noise=0.1)\n",
    "swiss_roll = swiss_roll[:, [0, 2]]/10.0\n",
    "\n",
    "s_curve, _= make_s_curve(10**4, noise=0.1)\n",
    "s_curve = s_curve[:, [0, 2]]/10.0\n",
    "\n",
    "moons, _ = make_moons(10**4, noise=0.1)\n",
    "\n",
    "data = s_curve.T\n",
    "#dataset = torch.Tensor(data.T).float()\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(20,5))\n",
    "\n",
    "axes[0].scatter(*data, alpha=0.5, color='white', edgecolor='gray', s=5);\n",
    "axes[0].axis('off')\n",
    "\n",
    "data = swiss_roll.T\n",
    "axes[1].scatter(*data, alpha=0.5, color='white', edgecolor='gray', s=5);\n",
    "axes[1].axis('off')\n",
    "#dataset = torch.Tensor(data.T).float()\n",
    "\n",
    "data = moons.T\n",
    "axes[2].scatter(*data, alpha=0.5, color='white', edgecolor='gray', s=3);\n",
    "axes[2].axis('off')\n",
    "dataset = torch.Tensor(data.T).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "#betas = torch.tensor([1.7e-5] * num_steps)\n",
    "betas = make_beta_schedule(schedule='sigmoid', n_timesteps=num_steps, start=1e-5, end=0.5e-2)\n",
    "\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_x(x_0, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "    alphas_t = extract(alphas_bar_sqrt, t, x_0)\n",
    "    alphas_1_m_t = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    return (alphas_t * x_0 + alphas_1_m_t * noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
    "for i in range(10):\n",
    "    q_i = q_x(dataset, torch.tensor([i * 10]))\n",
    "    axs[i].scatter(q_i[:, 0], q_i[:, 1],color='white',edgecolor='gray', s=5);\n",
    "    axs[i].set_axis_off(); axs[i].set_title('$q(\\mathbf{x}_{'+str(i*10)+'})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_coef_1 = (betas * torch.sqrt(alphas_prod_p) / (1 - alphas_prod))\n",
    "posterior_mean_coef_2 = ((1 - alphas_prod_p) * torch.sqrt(alphas) / (1 - alphas_prod))\n",
    "posterior_variance = betas * (1 - alphas_prod_p) / (1 - alphas_prod)\n",
    "posterior_log_variance_clipped = torch.log(torch.cat((posterior_variance[1].view(1, 1), posterior_variance[1:].view(-1, 1)), 0)).view(-1)\n",
    "\n",
    "def q_posterior_mean_variance(x_0, x_t, t):\n",
    "    coef_1 = extract(posterior_mean_coef_1, t, x_0)\n",
    "    coef_2 = extract(posterior_mean_coef_2, t, x_0)\n",
    "    mean = coef_1 * x_0 + coef_2 * x_t\n",
    "    var = extract(posterior_log_variance_clipped, t, x_0)\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Moving Average Class\n",
    "# Orignal source: https://github.com/acids-ircam/diffusion_models\n",
    "\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An Implementation of Diffusion Network Model\n",
    "#Oringinal source: https://github.com/acids-ircam/diffusion_models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "        \n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin4 = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        x = F.softplus(self.lin3(x, y))\n",
    "        return self.lin4(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = ConditionalModel(num_steps)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#dataset = torch.tensor(data.T).float()\n",
    "# Create EMA model\n",
    "ema = EMA(0.9)\n",
    "ema.register(model)\n",
    "# Batch size\n",
    "batch_size = 128\n",
    "for t in range(1000):\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(dataset.size()[0])\n",
    "    for i in range(0, dataset.size()[0], batch_size):\n",
    "        # Retrieve current batch\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x = dataset[indices]\n",
    "        # Compute the loss.\n",
    "        loss = noise_estimation_loss(model, batch_x,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,num_steps)\n",
    "        # Before the backward pass, zero all of the network gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass: compute gradient of the loss with respect to parameters\n",
    "        loss.backward()\n",
    "        # Perform gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        # Calling the step function to update the parameters\n",
    "        optimizer.step()\n",
    "        # Update the exponential moving average\n",
    "        ema.update(model)\n",
    "    # Print loss\n",
    "    if (t % 100 == 0):\n",
    "        print(loss)\n",
    "        x_seq = p_sample_loop(model, dataset.shape,num_steps,alphas,betas,one_minus_alphas_bar_sqrt)\n",
    "        fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
    "        for i in range(1, 11):\n",
    "            cur_x = x_seq[i * 10].detach()\n",
    "            axs[i-1].scatter(cur_x[:, 0], cur_x[:, 1],color='white',edgecolor='gray', s=5);\n",
    "            axs[i-1].set_axis_off(); \n",
    "            axs[i-1].set_title('$q(\\mathbf{x}_{'+str(i*100)+'})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the forward image sequence\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "imgs = []\n",
    "#fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
    "for i in range(100):\n",
    "    plt.clf()\n",
    "    q_i = q_x(dataset, torch.tensor([i]))\n",
    "    plt.scatter(q_i[:, 0], q_i[:, 1],color='white',edgecolor='gray', s=5);\n",
    "    plt.axis('off'); \n",
    "    \n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    img = Image.open(img_buf)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the reverse diffusion sequence\n",
    "\n",
    "reverse = []\n",
    "for i in range(100):  \n",
    "    plt.clf()\n",
    "    cur_x = x_seq[i].detach()\n",
    "    plt.scatter(cur_x[:, 0], cur_x[:, 1],color='white',edgecolor='gray', s=5);\n",
    "    plt.axis('off')\n",
    "    \n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    img = Image.open(img_buf)\n",
    "    reverse.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs + reverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0].save(\"diffusion.gif\", format='GIF', append_images=imgs,save_all=True, duration=100, loop=0)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
